{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retina Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\내 드라이브\\\\Pytorch_Retinaface'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3126016737.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    cd G:/내 드라이브/Pytorch_Retinaface\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Retina Face train.py 폴더\n",
    "cd G:/내 드라이브/Pytorch_Retinaface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "#!python train.py --network mobile0.25 --training_dataset ../dataset/wider_face/train/label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\내 드라이브\\Pytorch_Retinaface\n"
     ]
    }
   ],
   "source": [
    "cd G:/내 드라이브/Pytorch_Retinaface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from models.retinaface import RetinaFace\n",
    "from data import cfg_mnet, cfg_re50\n",
    "\n",
    "from layers.functions.prior_box import PriorBox\n",
    "from utils.nms.py_cpu_nms import py_cpu_nms\n",
    "from utils.box_utils import decode, decode_landm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. HyperParmeter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- MobileNet 0.25 ---#\n",
    "weight_path = './weights/mobilenet0.25_Final.pth'\n",
    "cfg = cfg_mnet\n",
    "\n",
    "# #--- Resnet-50 ---#\n",
    "# weight_path = './weights/Resnet50_Final.pth'\n",
    "# cfg = cfg_re50\n",
    "\n",
    "resize = 1                      # image resize\n",
    "confidence_threshold = 0.02\n",
    "top_k = 5000\n",
    "nms_threshold = 0.4\n",
    "keep_top_k = 750\n",
    "vis_thres = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n",
      "Model Loaded on 'cuda'!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device : {device}\")\n",
    "\n",
    "model = RetinaFace(cfg, phase = 'test').to(device)\n",
    "model.load_state_dict(torch.load(weight_path, map_location=device))     # map_location : 학습환경과 별개로 eval device 설정\n",
    "model.eval()\n",
    "print(f\"Model Loaded on '{device}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Retinaface Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retinaface_inf(test_img, model):\n",
    "    img = np.float32(test_img)\n",
    "    img_height, img_width, _ = img.shape\n",
    "\n",
    "    scale = torch.Tensor([img_width, img_height, img_width, img_height])\n",
    "    img -= (104, 117, 123)\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    scale = scale.to(device)\n",
    "\n",
    "    tic = time.time()\n",
    "    loc, conf, landms = model(img)  # Forward-pass\n",
    "\n",
    "    # prior_data #\n",
    "    priorbox = PriorBox(cfg, image_size=(img_height, img_width))\n",
    "    prior_data = priorbox.forward().to(device).data\n",
    "    # boxes #\n",
    "    boxes = decode(loc.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    boxes = (boxes * scale / resize).cpu().numpy()\n",
    "    # scores #\n",
    "    scores = conf.squeeze(0).data.cpu().numpy()[:, 1]\n",
    "    # landms #\n",
    "    landms = decode_landm(landms.data.squeeze(0), prior_data, cfg['variance'])\n",
    "    scale1 = torch.Tensor([img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2], \n",
    "                           img.shape[3], img.shape[2], \n",
    "                           img.shape[3], img.shape[2],\n",
    "                           img.shape[3], img.shape[2]]).to(device)\n",
    "    \n",
    "    landms = (landms * scale1 / resize).cpu().numpy()\n",
    "\n",
    "    # Filter low score boxes\n",
    "    inds = np.where(scores > confidence_threshold)[0]\n",
    "    boxes = boxes[inds]\n",
    "    scores = scores[inds]\n",
    "    landms = landms[inds]\n",
    "\n",
    "    # keep top-K before NMS\n",
    "    order = scores.argsort()[::-1][:top_k]\n",
    "    boxes = boxes[order]\n",
    "    scores = scores[order]\n",
    "\n",
    "    # NMS Processing\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32, copy=False)\n",
    "    keep = py_cpu_nms(dets, nms_threshold)\n",
    "    dets = dets[keep, :]\n",
    "\n",
    "    # Keep top-K faster NMS\n",
    "    dets = dets[:keep_top_k, :]\n",
    "\n",
    "    # dets = np.concatenate((data, landms), axis=1)\n",
    "    print('Net Forward time: {:.4f}'.format(time.time() - tic))\n",
    "    print('fps_ :', round(1/(time.time() - tic), 2))\n",
    "\n",
    "    # draw box\n",
    "    for b in dets:\n",
    "        if b[4] < vis_thres:\n",
    "            continue\n",
    "        text = \"{:.4f}\".format(b[4])\n",
    "        b = list(map(int, b))\n",
    "        cv2.rectangle(test_img, (b[0], b[1]), (b[2], b[3]), (255, 0, 0), 2)\n",
    "        # cv2.putText()\n",
    "    \n",
    "    return test_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "detect_num = 30\n",
    "itr = 0\n",
    "test_path = test_path = '../dataset/wider_face/test/images/0--Parade'\n",
    "for img_path in glob.glob(test_path+\"/*.jpg\"):\n",
    "    test_img = cv2.imread(img_path)\n",
    "    detect_img = result_retina = retinaface_inf(test_img, model)\n",
    "    plt.imshow(cv2.cvtColor(detect_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    itr += 1\n",
    "    if itr > detect_num: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
